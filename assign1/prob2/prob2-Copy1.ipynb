{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "pd.options.mode.chained_assignment = None \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.io.parsers.read_csv('a1_d3.txt', sep='\\t',names=['data','value'])\n",
    "dataset['data'] = dataset['data'].str.lower()\n",
    "stop = [\"ive\",\"iam\",\"im\",\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "alphabets = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "dataset['data'] = dataset['data'].str.replace(r'[-,\\.&!\\+\\'0-9;\"\\(\\)/#@$*%^&?~`:'']','',regex=False)\n",
    "dataset['data'] = list(map(str.split, dataset['data']))\n",
    "dataset['data'] = dataset['data'].apply(lambda x: [item for item in x if item not in stop])\n",
    "dataset['data'] = dataset['data'].apply(lambda x: [item for item in x if item not in alphabets])\n",
    "dataset['data'] = dataset['data'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "# dataset = dataset.sample(frac=1)\n",
    "dataset = np.array_split(dataset,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755\n",
      "0.785\n",
      "0.695\n",
      "0.675\n",
      "0.75\n",
      "73.2 +/- 4.069397989875161\n"
     ]
    }
   ],
   "source": [
    "val=0\n",
    "array = np.zeros(5)\n",
    "for temp in range(5):\n",
    "    frames = [dataset[0],dataset[1],dataset[2],dataset[3],dataset[4]]\n",
    "    frames.pop(temp)\n",
    "    train_set = pd.concat(frames)\n",
    "    test_set = dataset[temp]\n",
    "    x_train = train_set['data']\n",
    "    y_train = train_set['value']\n",
    "    x_test = test_set['data']\n",
    "    y_test = test_set['value']\n",
    "    zeroes = (y_train==0).sum(axis=0)\n",
    "    ones = (y_train==1).sum(axis=0)\n",
    "    x_train1 = x_train[y_train==1]\n",
    "    x_train0 = x_train[y_train==0]\n",
    "    dict1 = {}\n",
    "    for data in x_train1:\n",
    "        for item in data:\n",
    "            dict1[item] = 0\n",
    "    for data in x_train1:\n",
    "        for item in data:\n",
    "            dict1[item] +=1\n",
    "    dict1 = pd.DataFrame(dict1.items(),columns=['word','freq'])\n",
    "    unique_words1 = len(dict1.index)\n",
    "    alpha = 1\n",
    "    total_words1 = np.sum(dict1['freq'])\n",
    "    temp1 = total_words1 + unique_words1\n",
    "#     dict1['prob'] = (dict1['freq'] + alpha)/(temp1)\n",
    "    dict1['prob'] = dict1['freq']/total_words1\n",
    "    dict = {}\n",
    "    for data in x_train0:\n",
    "        for item in data:\n",
    "            dict[item] = 0\n",
    "    for data in x_train0:\n",
    "        for item in data:\n",
    "                dict[item] +=1\n",
    "    dict0 = pd.DataFrame(dict.items(),columns=['word','freq'])\n",
    "    unique_words0 = len(dict0.index)\n",
    "    total_words0 = np.sum(dict0['freq'])\n",
    "    temp0 = total_words0 + unique_words0\n",
    "#     dict0['prob'] = (dict0['freq'] + alpha)/(temp0)\n",
    "    dict0['prob'] = dict0['freq']/total_words0\n",
    "    x_test = pd.DataFrame(x_test,columns=['data','prob1','prob0'])\n",
    "    x_test['prob1'] = 0.0\n",
    "    x_test['prob0'] = 0.0\n",
    "    x_test = x_test.reset_index(inplace=False,drop=True)\n",
    "    i=0\n",
    "    for data in x_test['data']:\n",
    "        for item in data:\n",
    "            if item in dict1.values:\n",
    "                x_test['prob1'][i] += np.log(dict1.loc[dict1['word']==item,'prob'])\n",
    "            else:\n",
    "                x_test['prob1'][i] += np.log(1/(temp1))\n",
    "        i += 1 \n",
    "    i=0\n",
    "    for data in x_test['data']:\n",
    "        for item in data:\n",
    "            if item in dict0.values:\n",
    "                x_test['prob0'][i] += np.log(dict0.loc[dict0['word']==item,'prob'])\n",
    "            else:\n",
    "                x_test['prob0'][i] += np.log(1/(temp0))\n",
    "        i += 1\n",
    "    zeroes = (y_train==0).sum(axis=0)/y_train.size\n",
    "    ones = (y_train==1).sum(axis=0)/y_train.size\n",
    "    x_test['prob1'] = x_test['prob1'] \n",
    "    x_test['prob0'] = x_test['prob0'] \n",
    "    ans = x_test['prob1']>x_test['prob0']\n",
    "    ans = ans.astype(int)\n",
    "    ans = np.array(ans)\n",
    "    y_test = np.array(y_test)\n",
    "    arr = (ans==y_test).sum()\n",
    "    print(arr/200)\n",
    "    array[temp] = arr/y_test.size\n",
    "print(np.mean(array)*100,\"+/-\",np.std(array)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
